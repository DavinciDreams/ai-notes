<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Notes Test</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .test-button {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
            margin: 10px 0;
            display: block;
            width: 100%;
        }
        .test-button:hover {
            background: #45a049;
        }
        .test-button:disabled {
            background: #cccccc;
            cursor: not-allowed;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 6px;
            font-weight: 500;
        }
        .status.success { background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
        .status.error { background: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
        .status.info { background: #d1ecf1; color: #0c5460; border: 1px solid #bee5eb; }
        .log {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 6px;
            padding: 15px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            white-space: pre-wrap;
            max-height: 400px;
            overflow-y: auto;
            margin: 20px 0;
        }
        h1 { color: #333; margin-bottom: 30px; }
        h2 { color: #666; margin-top: 30px; margin-bottom: 15px; }
        .record-btn {
            background: #dc3545;
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 18px;
            font-weight: bold;
            margin: 20px 0;
            display: block;
            width: 200px;
            margin-left: auto;
            margin-right: auto;
        }
        .record-btn:hover { background: #c82333; }
        .record-btn.recording { 
            background: #ff4757; 
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        .transcription-result {
            background: #f8f9fa;
            border: 2px solid #007bff;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            min-height: 60px;
            font-size: 16px;
            line-height: 1.5;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Notes Test Page</h1>
        <p>This page tests the voice notes transcription functionality for the AI Notes application.</p>
        
        <h2>1. Service Status Check</h2>
        <button class="test-button" onclick="checkServices()">Check Backend Services</button>
        <div id="serviceStatus"></div>
        
        <h2>2. Voice Recording Test</h2>
        <button class="record-btn" id="recordBtn" onclick="toggleRecording()">üé§ Start Recording</button>
        <div id="recordingStatus"></div>
        <div id="transcriptionResult" class="transcription-result" style="display: none;">
            <strong>Transcription:</strong>
            <div id="transcriptionText"></div>
        </div>
        
        <h2>3. API Test with Sample Audio</h2>
        <button class="test-button" onclick="testWithSampleAudio()">Test API with Generated Audio</button>
        
        <div id="log" class="log"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        function log(message, type = 'info') {
            const logDiv = document.getElementById('log');
            const timestamp = new Date().toLocaleTimeString();
            const logMessage = `[${timestamp}] ${message}\n`;
            logDiv.textContent += logMessage;
            logDiv.scrollTop = logDiv.scrollHeight;
            console.log(message);
        }

        function showStatus(elementId, message, type = 'info') {
            const element = document.getElementById(elementId);
            element.innerHTML = `<div class="status ${type}">${message}</div>`;
        }

        async function checkServices() {
            log('üîç Checking backend services...');
            
            try {
                // Test backend API
                const backendResponse = await fetch('http://localhost:3002/', { method: 'GET' });
                if (backendResponse.ok) {
                    log('‚úÖ Backend API (port 3002): OK');
                } else {
                    log(`‚ö†Ô∏è Backend API (port 3002): ${backendResponse.status}`);
                }
            } catch (error) {
                log(`‚ùå Backend API (port 3002): ${error.message}`);
            }

            try {
                // Test Whisper service
                const whisperResponse = await fetch('http://localhost:9002/', { method: 'GET' });
                if (whisperResponse.ok) {
                    log('‚úÖ Whisper Service (port 9002): OK');
                } else {
                    log(`‚ö†Ô∏è Whisper Service (port 9002): ${whisperResponse.status}`);
                }
            } catch (error) {
                log(`‚ùå Whisper Service (port 9002): ${error.message}`);
            }

            showStatus('serviceStatus', 'Service check complete. See log for details.', 'info');
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                await stopRecording();
            }
        }

        async function startRecording() {
            try {
                log('üé§ Requesting microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    log('‚èπÔ∏è Recording stopped, processing audio...');
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    log(`üìé Audio blob created: ${audioBlob.size} bytes`);
                    
                    await transcribeAudio(audioBlob);
                    
                    // Stop all tracks
                    stream.getTracks().forEach(track => track.stop());
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                const recordBtn = document.getElementById('recordBtn');
                recordBtn.textContent = '‚èπÔ∏è Stop Recording';
                recordBtn.classList.add('recording');
                
                showStatus('recordingStatus', 'üî¥ Recording... Click stop when finished.', 'info');
                log('‚úÖ Recording started successfully');
                
            } catch (error) {
                log(`‚ùå Recording failed: ${error.message}`);
                showStatus('recordingStatus', `Error: ${error.message}`, 'error');
            }
        }

        async function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                const recordBtn = document.getElementById('recordBtn');
                recordBtn.textContent = 'üé§ Start Recording';
                recordBtn.classList.remove('recording');
                
                showStatus('recordingStatus', '‚è≥ Processing recording...', 'info');
            }
        }

        async function transcribeAudio(audioBlob) {
            try {
                log('üì° Sending audio to transcription API...');
                
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.wav');
                
                const response = await fetch('http://localhost:3002/api/ai/transcribe', {
                    method: 'POST',
                    body: formData
                });
                
                log(`üì• API Response: ${response.status} ${response.statusText}`);
                
                if (response.ok) {
                    const result = await response.json();
                    log(`üìù Transcription result: ${JSON.stringify(result)}`);
                    
                    const transcriptionDiv = document.getElementById('transcriptionResult');
                    const transcriptionText = document.getElementById('transcriptionText');
                    
                    if (result.text && result.text.trim()) {
                        transcriptionText.textContent = result.text;
                        transcriptionDiv.style.display = 'block';
                        showStatus('recordingStatus', '‚úÖ Transcription completed!', 'success');
                        log(`üéâ SUCCESS: "${result.text}"`);
                    } else {
                        transcriptionText.textContent = 'No speech detected or transcription was empty.';
                        transcriptionDiv.style.display = 'block';
                        showStatus('recordingStatus', '‚ö†Ô∏è No speech detected in recording.', 'error');
                        log('‚ö†Ô∏è Transcription returned empty text');
                    }
                } else {
                    const errorText = await response.text();
                    log(`‚ùå Transcription API error: ${errorText}`);
                    showStatus('recordingStatus', `API Error: ${response.status}`, 'error');
                }
                
            } catch (error) {
                log(`‚ùå Transcription failed: ${error.message}`);
                showStatus('recordingStatus', `Transcription Error: ${error.message}`, 'error');
            }
        }

        async function testWithSampleAudio() {
            log('üß™ Testing with generated sample audio...');
            
            try {
                // Create a simple audio blob with a tone
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const sampleRate = audioContext.sampleRate;
                const duration = 2; // 2 seconds
                const frameCount = sampleRate * duration;
                const arrayBuffer = audioContext.createBuffer(1, frameCount, sampleRate);
                
                // Generate a simple tone pattern
                const channelData = arrayBuffer.getChannelData(0);
                for (let i = 0; i < frameCount; i++) {
                    // Create a melody with different frequencies
                    const time = i / sampleRate;
                    const freq = 440 + Math.sin(time * 2) * 100; // Varying frequency
                    channelData[i] = Math.sin(2 * Math.PI * freq * time) * 0.1;
                }
                
                // Convert to WAV
                const wavArrayBuffer = audioBufferToWav(arrayBuffer);
                const audioBlob = new Blob([wavArrayBuffer], { type: 'audio/wav' });
                
                log(`üìé Generated sample audio: ${audioBlob.size} bytes`);
                await transcribeAudio(audioBlob);
                
            } catch (error) {
                log(`‚ùå Sample audio test failed: ${error.message}`);
            }
        }

        // WAV encoder function
        function audioBufferToWav(buffer) {
            const length = buffer.length;
            const sampleRate = buffer.sampleRate;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            const channelData = buffer.getChannelData(0);
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return arrayBuffer;
        }

        // Auto-check services on page load
        window.addEventListener('load', () => {
            log('üöÄ Voice Notes Test Page Loaded');
            checkServices();
        });
    </script>
</body>
</html>
